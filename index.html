<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Marco P. Apolinario </title> <meta name="author" content="Marco P. Apolinario"> <meta name="description" content="This is my personal academic website where I will share some info about the projects I am working on, my research interests, and some news. Also, I will publish a blog focus on topics about neuromorphic computing, computer vision, and applications."> <meta name="keywords" content="ai, neuromorphic, academic-website, vlsi, snn"> <meta property="og:site_name" content="Marco P. Apolinario"> <meta property="og:type" content="website"> <meta property="og:title" content="Marco P. Apolinario | About"> <meta property="og:url" content="https://mapolinario94.github.io/"> <meta property="og:description" content="This is my personal academic website where I will share some info about the projects I am working on, my research interests, and some news. Also, I will publish a blog focus on topics about neuromorphic computing, computer vision, and applications."> <meta property="og:image" content="https://mapolinario94.github.io/assets/img/prof.jpg"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="About"> <meta name="twitter:description" content="This is my personal academic website where I will share some info about the projects I am working on, my research interests, and some news. Also, I will publish a blog focus on topics about neuromorphic computing, computer vision, and applications."> <meta name="twitter:image" content="https://mapolinario94.github.io/assets/img/prof.jpg"> <meta name="twitter:site" content="@mapolinario94"> <meta name="twitter:creator" content="@mapolinario94"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Marco P. Apolinario"
        },
        "url": "https://mapolinario94.github.io/",
        "@type": "WebSite",
        "description": "This is my personal academic website where I will share some info about the projects I am working on, my research interests, and some news. Also, I will publish a blog focus on topics about neuromorphic computing, computer vision, and applications.",
        "headline": "About",
        
        "sameAs": ["https://orcid.org/0000-0002-1124-2545", "https://scholar.google.com/citations?user=a9JiVBQAAAAJ", "https://publons.com/a/AAU-5047-2020/", "https://www.researchgate.net/profile/Marco_Apolinario", "https://github.com/mapolinario94", "https://www.linkedin.com/in/marco-apolinario", "https://twitter.com/mapolinario94"],
        
        "name": "Marco P. Apolinario",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mapolinario94.github.io/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Marco</span> P. Apolinario </h1> <p class="desc"><a href="#">Graduate Research Assistant at Purdue University</a>. B.Sc. in Electronics Engineering</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof-480.webp 480w,/assets/img/prof-800.webp 800w,/assets/img/prof-1400.webp 1400w," sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/prof.jpg?d0a651fae7dc941c7cca516e432a9b9e" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>EE 350, Purdue University</p> <p>501 Northwestern Ave</p> <p>West Lafayette, IN 47907</p> </div> </div> <div class="clearfix"> <p>I am a Ph.D. student in Electrical and Computer Engineering at Purdue University, under the guidance of Professor Kaushik Roy in the <a href="https://engineering.purdue.edu/NRL" target="\_blank" rel="external nofollow noopener">Nanoelectronics Research Lab</a>. I earned my B.Sc. in Electronics Engineering from the National University of Engineering (UNI), Peru, in 2017. Over the years, I have gathered valuable experience, including a research internship at the Jicamarca Radio Observatory (JRO) and a Research Assistant role at the Signal and Image Processing Lab at INICTEL-UNI, Peru. In 2020, I was honored to receive the fully-funded ‘Beca Presidente de la Republica’ graduate scholarship from the Peruvian Government (PRONABEC), and in 2023, I pursued a research internship at Kilby Labs, Texas Instruments.</p> <p>My research focus revolves around hardware/software co-design for brain-inspired computing. I am passionate about leveraging insights from biological mechanisms to develop more efficient artificial intelligence models.</p> </div> <h2> <a href="/news/" style="color: inherit">News</a> </h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jan 07, 2025</th> <td> My latest research <a href="https://openreview.net/forum?id=CNaiJRcX84" rel="external nofollow noopener" target="_blank">paper</a> on temporal local learning rules for SNN got accepted at <a href="https://openreview.net/forum?id=CNaiJRcX84" rel="external nofollow noopener" target="_blank">Transactions on Machine Learning Research (TMLR)</a>! </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 04, 2024</th> <td> <a class="news-title" href="/news/2024-11-04-utwente/">Gave a seminar on my research on local learning rules for DNNs at the University of Twente!</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 29, 2024</th> <td> My latest research <a href="https://arxiv.org/abs/2405.15868" rel="external nofollow noopener" target="_blank">paper</a> on local learning rules for DNN got accepted at <a href="https://wacv2025.thecvf.com/" rel="external nofollow noopener" target="_blank">IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2025</a>! </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 16, 2024</th> <td> <a class="news-title" href="/news/2024-09-16-neuropac_fellowship/">I've been awarded the NSF AccelNet NeuroPAC Fellowship to join TU Delft during the Fall 2024!</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 11, 2024</th> <td> <a class="news-title" href="/news/2024-09-11-techcon/">Presented my research on local learning rules at SRC's TECHCON 2024!</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 20, 2024</th> <td> <a class="news-title" href="/news/2024-07-20-telluride/">I had an awesome time at the Telluride Neuromorphic Engineering Workshop 2024!</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 27, 2024</th> <td> <a class="news-title" href="/news/2024-06-20-dac2024/">Presented my research on in-memory computing at DAC 2024!</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 02, 2024</th> <td> My co-authored review paper, unearthing the potential of SNNs, has been accepted for presentation at <a href="https://www.date-conference.com/programme#Wednesday" rel="external nofollow noopener" target="_blank">DATE 2024</a>! </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 23, 2023</th> <td> My first paper as a PhD student has been accepted at <a href="https://ieeexplore.ieee.org/document/10260275" rel="external nofollow noopener" target="_blank">IEEE Transactions on Emerging Topic in Computing</a>!! </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 24, 2023</th> <td> My co-authored <a href="https://arxiv.org/abs/2211.10754" rel="external nofollow noopener" target="_blank">paper</a> on event-based image segmentation got accepted at <a href="https://wacv2024.thecvf.com/" rel="external nofollow noopener" target="_blank">IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024</a>! </td> </tr> </table> </div> </div> <h2> <a href="/blog/" style="color: inherit">Latest Posts</a> </h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">Selected Publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge" style="background-color:#07DFD5"><a href="https://wacv2025.thecvf.com/" rel="external nofollow noopener" target="_blank">WACV</a></abbr> </div> <div id="Apolinario2025b" class="col-sm-8"> <div class="title">LLS: Local Learning Rule for Deep Neural Networks Inspired by Neural Activity Synchronization</div> <div class="author"> <em>M. P. E. Apolinario</em>, A. Roy , and K. Roy </div> <div class="periodical"> <em>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2405.15868" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://openaccess.thecvf.com/content/WACV2025/html/Apolinario_LLS_Local_Learning_Rule_for_Deep_Neural_Networks_Inspired_by_WACV_2025_paper.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/mapolinario94/LLS-DNN" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Training deep neural networks (DNNs) using traditional backpropagation (BP) presents challenges in terms of computational complexity and energy consumption, particularly for on-device learning where computational resources are limited. Various alternatives to BP, including random feedback alignment, forward-forward, and local classifiers, have been explored to address these challenges. These methods have their advantages, but they can encounter difficulties when dealing with intricate visual tasks or demand considerable computational resources. In this paper, we propose a novel Local Learning rule inspired by neural activity Synchronization phenomena (LLS) observed in the brain. LLS utilizes fixed periodic basis vectors to synchronize neuron activity within each layer, enabling efficient training without the need for additional trainable parameters. We demonstrate the effectiveness of LLS and its variations, LLS-M and LLS-MxM, on multiple image classification datasets, achieving accuracy comparable to BP with reduced computational complexity and minimal additional parameters. Furthermore, the performance of LLS on the Visual Wake Word (VWW) dataset highlights its suitability for on-device learning tasks, making it a promising candidate for edge hardware implementations.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge" style="background-color:#00369f"><a href="https://cvpr.thecvf.com/" rel="external nofollow noopener" target="_blank">ICCV</a></abbr> </div> <div id="Apolinario2025c" class="col-sm-8"> <div class="title">CODE-CL: Conceptor-Based Gradient Projection for Deep Continual Learning</div> <div class="author"> <em>M. P. E. Apolinario</em>, S. Choudhary , and K. Roy </div> <div class="periodical"> <em>International Conference on Computer Vision (ICCV)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2411.15235" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>Continual learning (CL) - the ability to progressively acquire and integrate new concepts - is essential to intelligent systems to adapt to dynamic environments. However, deep neural networks struggle with catastrophic forgetting (CF) when learning tasks sequentially, as training for new tasks often overwrites previously learned knowledge. To address this, recent approaches constrain updates to orthogonal subspaces using gradient projection, effectively preserving important gradient directions for previous tasks. While effective in reducing forgetting, these approaches inadvertently hinder forward knowledge transfer (FWT), particularly when tasks are highly correlated. In this work, we propose Conceptor-based gradient projection for Deep Continual Learning (CODE-CL), a novel method that leverages conceptor matrix representations, a form of regularized reconstruction, to adaptively handle highly correlated tasks. CODE-CL mitigates CF by projecting gradients onto pseudo-orthogonal subspaces of previous task feature spaces while simultaneously promoting FWT. It achieves this by learning a linear combination of shared basis directions, allowing efficient balance between stability and plasticity and transfer of knowledge between overlapping input feature representations. Extensive experiments on continual learning benchmarks validate CODE-CL’s efficacy, demonstrating superior performance, reduced forgetting, and improved FWT as compared to state-of-the-art methods.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge" style="background-color:#0b7002"><a href="">IJCNN</a></abbr> </div> <div id="Apolinario2025d" class="col-sm-8"> <div class="title">TESS: A Scalable Temporally and Spatially Local Learning Rule for Spiking Neural Networks</div> <div class="author"> <em>M. P. E. Apolinario</em>, K. Roy , and C. Frenkel </div> <div class="periodical"> <em>International Joint Conference on Neural Networks (IJCNN)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2502.01837" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/mapolinario94/TESS" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>The demand for low-power inference and training of deep neural networks (DNNs) on edge devices has intensified the need for algorithms that are both scalable and energy-efficient. While spiking neural networks (SNNs) allow for efficient inference by processing complex spatio-temporal dynamics in an event-driven fashion, training them on resource-constrained devices remains challenging due to the high computational and memory demands of conventional error backpropagation (BP)-based approaches. In this work, we draw inspiration from biological mechanisms such as eligibility traces, spike-timing-dependent plasticity, and neural activity synchronization to introduce TESS, a temporally and spatially local learning rule for training SNNs. Our approach addresses both temporal and spatial credit assignments by relying solely on locally available signals within each neuron, thereby allowing computational and memory overheads to scale linearly with the number of neurons, independently of the number of time steps. Despite relying on local mechanisms, we demonstrate performance comparable to the backpropagation through time (BPTT) algorithm, within ∼1.4 accuracy points on challenging computer vision scenarios relevant at the edge, such as the IBM DVS Gesture dataset, CIFAR10-DVS, and temporal versions of CIFAR10, and CIFAR100. Being able to produce comparable performance to BPTT while keeping low time and memory complexity, TESS enables efficient and scalable on-device learning at the edge.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">TMLR</abbr> </div> <div id="Apolinario2025a" class="col-sm-8"> <div class="title">S-TLLR: STDP-inspired Temporal Local Learning Rule for Spiking Neural Networks</div> <div class="author"> <em>M. P. E. Apolinario</em>, and K. Roy </div> <div class="periodical"> <em>Transactions on Machine Learning Research (TMLR)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2306.15220" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://openreview.net/forum?id=CNaiJRcX84" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/mapolinario94/S-TLLR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Spiking Neural Networks (SNNs) are biologically plausible models that have been identified as potentially apt for deploying energy-efficient intelligence at the edge, particularly for sequential learning tasks. However, training of SNNs poses significant challenges due to the necessity for precise temporal and spatial credit assignment. Back-propagation through time (BPTT) algorithm, whilst the most widely used method for addressing these issues, incurs high computational cost due to its temporal dependency. In this work, we propose S-TLLR, a novel three-factor temporal local learning rule inspired by the Spike-Timing Dependent Plasticity (STDP) mechanism, aimed at training deep SNNs on event-based learning tasks. Furthermore, S-TLLR is designed to have low memory and time complexities, which are independent of the number of time steps, rendering it suitable for online learning on low-power edge devices. To demonstrate the scalability of our proposed method, we have conducted extensive evaluations on event-based datasets spanning a wide range of applications, such as image and gesture recognition, audio classification, and optical flow estimation. S-TLLR achieves comparable accuracy to BPTT (within ±2% for most tasks), while reducing memory usage by 5-50× and multiply-accumulate (MAC) operations by 1.3-6.6×, particularly when updates are restricted to the last few time-steps.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge" style="background-color:#27C108"><a href="">TETC</a></abbr> </div> <div id="Apolinario2023" class="col-sm-8"> <div class="title">Hardware/Software co-design with ADC-Less In-memory Computing Hardware for Spiking Neural Networks</div> <div class="author"> <em>M. P. E. Apolinario</em>, A. Kosta , U. Saxena , and K. Roy </div> <div class="periodical"> <em>IEEE Transactions on Emerging Topics in Computing</em>, Sep 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2211.02167" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://doi.org/10.1109/TETC.2023.3316121" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Spiking Neural Networks (SNNs) are bio-plausible models that hold great potential for realizing energy-efficient implementations of sequential tasks on resource-constrained edge devices. However, commercial edge platforms based on standard GPUs are not optimized to deploy SNNs, resulting in high energy and latency. While analog In-Memory Computing (IMC) platforms can serve as energy-efficient inference engines, they are accursed by the immense energy, latency, and area requirements of high-precision ADCs (HP-ADC), overshadowing the benefits of in-memory computations. We propose a hardware/software co-design methodology to deploy SNNs into an ADC-Less IMC architecture using sense-amplifiers as 1-bit ADCs replacing conventional HP-ADCs and alleviating the above issues. Our proposed framework incurs minimal accuracy degradation by performing hardware-aware training and is able to scale beyond simple image classification tasks to more complex sequential regression tasks. Experiments on complex tasks of optical flow estimation and gesture recognition show that progressively increasing the hardware awareness during SNN training allows the model to adapt and learn the errors due to the non-idealities associated with ADC-Less IMC. Also, the proposed ADC-Less IMC offers significant energy and latency improvements, 2−7× and 8.9−24.6×, respectively, depending on the SNN model and the workload, compared to HP-ADC IMC.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6D%61%70%6F%6C%69%6E%61@%70%75%72%64%75%65.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://orcid.org/0000-0002-1124-2545" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=a9JiVBQAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://publons.com/a/AAU-5047-2020/" title="Publons" rel="external nofollow noopener" target="_blank"><i class="ai ai-publons"></i></a> <a href="https://www.researchgate.net/profile/Marco_Apolinario/" title="ResearchGate" rel="external nofollow noopener" target="_blank"><i class="ai ai-researchgate"></i></a> <a href="https://github.com/mapolinario94" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/marco-apolinario" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/mapolinario94" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> </div> <div class="contact-note"></div> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Marco P. Apolinario. Last updated: July 13, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-EWSV51N6WF"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-EWSV51N6WF");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>