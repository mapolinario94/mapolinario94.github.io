<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Beyond Backprop | Marco P. Apolinario </title> <meta name="author" content="Marco P. Apolinario"> <meta name="description" content="Teaching AI to Learn Like the Brain"> <meta name="keywords" content="ai, neuromorphic, academic-website, vlsi, snn"> <meta property="og:site_name" content="Marco P. Apolinario"> <meta property="og:type" content="website"> <meta property="og:title" content="Marco P. Apolinario | Beyond Backprop"> <meta property="og:url" content="https://mapolinario94.github.io/projects/1_beyond_backprop/"> <meta property="og:description" content="Teaching AI to Learn Like the Brain"> <meta property="og:image" content="https://mapolinario94.github.io/assets/img/beyond_backprop.png"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="Beyond Backprop"> <meta name="twitter:description" content="Teaching AI to Learn Like the Brain"> <meta name="twitter:image" content="https://mapolinario94.github.io/assets/img/beyond_backprop.png"> <meta name="twitter:site" content="@mapolinario94"> <meta name="twitter:creator" content="@mapolinario94"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Marco P. Apolinario"
        },
        "url": "https://mapolinario94.github.io/projects/1_beyond_backprop/",
        "@type": "WebSite",
        "description": "Teaching AI to Learn Like the Brain",
        "headline": "Beyond Backprop",
        
        "sameAs": ["https://orcid.org/0000-0002-1124-2545", "https://scholar.google.com/citations?user=a9JiVBQAAAAJ", "https://publons.com/a/AAU-5047-2020/", "https://www.researchgate.net/profile/Marco_Apolinario", "https://github.com/mapolinario94", "https://www.linkedin.com/in/marco-apolinario", "https://twitter.com/mapolinario94"],
        
        "name": "Marco P. Apolinario",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mapolinario94.github.io/projects/1_beyond_backprop/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Marco</span> P. Apolinario </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Beyond Backprop</h1> <p class="post-description">Teaching AI to Learn Like the Brain</p> </header> <article> <p>Deep neural networks today are powered by the backpropagation algorithm — a mathematical engine that computes global gradients by transmitting information backward through every layer and time step. Despite its success, this mechanism is neither efficient nor biologically plausible. It requires every neuron to know the state of all others, making learning energy-hungry and unsuitable for on-device intelligence. The human brain, in contrast, learns <strong>locally</strong>: each synapse adjusts its strength using only signals it can access — pre- and post-synaptic activity and modulatory feedback.</p> <p>My research explores a simple yet profound question:</p> <blockquote> <p><em>Can we teach artificial systems to learn the way the brain does — locally, efficiently, and continuously?</em></p> </blockquote> <p>This question guides my exploration of <strong>local learning rules</strong> — biologically inspired algorithms that replace global gradient propagation with mechanisms relying only on local information. The goal is to bring the power of deep learning closer to the remarkable efficiency and adaptability of the brain, enabling AI that can learn autonomously and on-device.</p> <p>The first step toward this goal was to address <strong>temporal locality</strong> — assigning credit in time without replaying an entire sequence of neural activations. In <strong>S-TLLR (Spike-Timing-Dependent Local Learning Rule)</strong> <a class="citation" href="#Apolinario2025stllr">(Apolinario &amp; Roy, 2025)</a>, we introduced a temporal local learning mechanism inspired by <em>spike-timing-dependent plasticity (STDP)</em>. Instead of backpropagating errors through time as in BPTT, S-TLLR computes instantaneous updates from causal and non-causal spike correlations modulated by a local learning signal. This design allows training to proceed online, using constant memory and computation, while matching backpropagation accuracy within a few percentage points. By relying only on locally accessible quantities, S-TLLR brings time-local learning to deep spiking models, opening a path toward scalable, energy-efficient on-device adaptation.</p> <p>Yet, while S-TLLR achieved temporal locality, it still relied on global feedback across layers. To achieve <strong>spatial locality</strong>, we developed <strong>LLS (Local Learning via Synchronization)</strong> <a class="citation" href="#Apolinario2025lls">(Apolinario et al., 2025)</a>, where each layer learns through coordinated oscillatory activity rather than backpropagated gradients. Inspired by synchronization phenomena observed in neural populations, LLS allows deep networks to train layer-wise using fixed local feedback, achieving competitive accuracy on benchmarks such as CIFAR-100 and TinyImageNet. This revealed that effective representation learning can arise from <em>self-organized synchronization</em> rather than explicit error signals.</p> <p>Building on these principles, <strong>TESS (Temporally and Spatially Local Learning Rule)</strong> <a class="citation" href="#Apolinario2025tess">(Apolinario et al., 2025)</a> unifies both time and space into a fully local learning framework. TESS combines STDP-like eligibility traces for temporal credit assignment with layer-wise synchronization mechanisms for spatial coordination, allowing each neuron to update its synapses using only locally available signals. Remarkably, TESS performs within 1.4 percentage points of backpropagation on event-based datasets such as CIFAR10-DVS and IBM DVS Gesture, while requiring over <strong>200× fewer computations</strong> and <strong>up to 10× less memory</strong>. This marks a step change in the design of neuromorphic algorithms — making on-device learning both practical and biologically grounded.</p> <p>Together, these studies trace the evolution from global gradient-based optimization toward <strong>biologically inspired local learning</strong>. They show that the key properties of deep learning — credit assignment, generalization, and continual adaptation — can emerge from local interactions between neurons, without any need for global error propagation. By coupling these insights with hardware-software co-design, our research envisions a future where intelligent systems learn autonomously, efficiently, and continuously — moving AI <strong>beyond backpropagation</strong> and closer to the learning principles of the brain.</p> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">TMLR</abbr> </div> <div id="Apolinario2025stllr" class="col-sm-8"> <div class="title">S-TLLR: STDP-inspired Temporal Local Learning Rule for Spiking Neural Networks</div> <div class="author"> <em>M. P. E. Apolinario</em>, and K. Roy </div> <div class="periodical"> <em>Transactions on Machine Learning Research (TMLR)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2306.15220" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://openreview.net/forum?id=CNaiJRcX84" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/mapolinario94/S-TLLR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/S-TLLR-Poster-MarcoApolinario-NeVi.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Spiking Neural Networks (SNNs) are biologically plausible models that have been identified as potentially apt for deploying energy-efficient intelligence at the edge, particularly for sequential learning tasks. However, training of SNNs poses significant challenges due to the necessity for precise temporal and spatial credit assignment. Back-propagation through time (BPTT) algorithm, whilst the most widely used method for addressing these issues, incurs high computational cost due to its temporal dependency. In this work, we propose S-TLLR, a novel three-factor temporal local learning rule inspired by the Spike-Timing Dependent Plasticity (STDP) mechanism, aimed at training deep SNNs on event-based learning tasks. Furthermore, S-TLLR is designed to have low memory and time complexities, which are independent of the number of time steps, rendering it suitable for online learning on low-power edge devices. To demonstrate the scalability of our proposed method, we have conducted extensive evaluations on event-based datasets spanning a wide range of applications, such as image and gesture recognition, audio classification, and optical flow estimation. S-TLLR achieves comparable accuracy to BPTT (within ±2% for most tasks), while reducing memory usage by 5-50× and multiply-accumulate (MAC) operations by 1.3-6.6×, particularly when updates are restricted to the last few time-steps.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge" style="background-color:#07DFD5"><a href="https://wacv2025.thecvf.com/" rel="external nofollow noopener" target="_blank">WACV</a></abbr> </div> <div id="Apolinario2025lls" class="col-sm-8"> <div class="title">LLS: Local Learning Rule for Deep Neural Networks Inspired by Neural Activity Synchronization</div> <div class="author"> <em>M. P. E. Apolinario</em>, A. Roy , and K. Roy </div> <div class="periodical"> <em>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2405.15868" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://openaccess.thecvf.com/content/WACV2025/html/Apolinario_LLS_Local_Learning_Rule_for_Deep_Neural_Networks_Inspired_by_WACV_2025_paper.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/mapolinario94/LLS-DNN" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Training deep neural networks (DNNs) using traditional backpropagation (BP) presents challenges in terms of computational complexity and energy consumption, particularly for on-device learning where computational resources are limited. Various alternatives to BP, including random feedback alignment, forward-forward, and local classifiers, have been explored to address these challenges. These methods have their advantages, but they can encounter difficulties when dealing with intricate visual tasks or demand considerable computational resources. In this paper, we propose a novel Local Learning rule inspired by neural activity Synchronization phenomena (LLS) observed in the brain. LLS utilizes fixed periodic basis vectors to synchronize neuron activity within each layer, enabling efficient training without the need for additional trainable parameters. We demonstrate the effectiveness of LLS and its variations, LLS-M and LLS-MxM, on multiple image classification datasets, achieving accuracy comparable to BP with reduced computational complexity and minimal additional parameters. Furthermore, the performance of LLS on the Visual Wake Word (VWW) dataset highlights its suitability for on-device learning tasks, making it a promising candidate for edge hardware implementations.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge" style="background-color:#0b7002"><a href="">IJCNN</a></abbr> </div> <div id="Apolinario2025tess" class="col-sm-8"> <div class="title">TESS: A Scalable Temporally and Spatially Local Learning Rule for Spiking Neural Networks</div> <div class="author"> <em>M. P. E. Apolinario</em>, K. Roy , and C. Frenkel </div> <div class="periodical"> <em>International Joint Conference on Neural Networks (IJCNN)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2502.01837" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/mapolinario94/TESS" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>The demand for low-power inference and training of deep neural networks (DNNs) on edge devices has intensified the need for algorithms that are both scalable and energy-efficient. While spiking neural networks (SNNs) allow for efficient inference by processing complex spatio-temporal dynamics in an event-driven fashion, training them on resource-constrained devices remains challenging due to the high computational and memory demands of conventional error backpropagation (BP)-based approaches. In this work, we draw inspiration from biological mechanisms such as eligibility traces, spike-timing-dependent plasticity, and neural activity synchronization to introduce TESS, a temporally and spatially local learning rule for training SNNs. Our approach addresses both temporal and spatial credit assignments by relying solely on locally available signals within each neuron, thereby allowing computational and memory overheads to scale linearly with the number of neurons, independently of the number of time steps. Despite relying on local mechanisms, we demonstrate performance comparable to the backpropagation through time (BPTT) algorithm, within ∼1.4 accuracy points on challenging computer vision scenarios relevant at the edge, such as the IBM DVS Gesture dataset, CIFAR10-DVS, and temporal versions of CIFAR10, and CIFAR100. Being able to produce comparable performance to BPTT while keeping low time and memory complexity, TESS enables efficient and scalable on-device learning at the edge.</p> </div> </div> </div> </li> </ol> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Marco P. Apolinario. Last updated: October 14, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-EWSV51N6WF"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-EWSV51N6WF");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>